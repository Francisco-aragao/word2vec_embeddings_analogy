{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Francisco Teixeira Rocha Aragão\n",
    "### 2021031726\n",
    "### Tp1 - Processamento de Linguagem Natural\n",
    "\n",
    "#### Objetivo: Testar diferentes variações de parametros para utilização do modelo Word2vec para a tarefa de verificação de analogias utilizando operações de subtração e adição de vetores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análise dos resultados\n",
    "\n",
    "O presente trabalho busca testar diferentes variações de parâmetros para construção do modelo Word2Vec. Dessa forma, o foco é testar o impacto em alterar alguns parâmetros importantes, como:\n",
    "- Implementação de Skip-gram ou CBOW\n",
    "- Tamanho da janela de contexto\n",
    "- Tamanho dos embeddings\n",
    "- Número de iterações (epochs)\n",
    "\n",
    "Desse modo, foi usado o arquivo 'text8' para avaliação do modelo Word2Vec, que foi treinado com o arquivo 'questions-words.txt'. O arquivo 'questions-words.txt' contém analogias do tipo \"a é para b, assim como c é para d\", e o objetivo é verificar se o modelo consegue encontrar a palavra d, dado a, b e c (executando assim operações vetorias de som e subtração para encontrar a palavra d). Os testes realizados foram feitos utilizando a similaridade de cosseno entre os vetores de palavras para encontrar a palavra d, e o erro foi calculado como a média de erro de classificação de analogias.\n",
    "\n",
    "Os resultados obtidos podem ser vistos ao final do notebook para diferentes iterações, testando uma combinação de diferentes parâmetros. dito isso, o melhor resultado obtido foram com os parâmetros: \n",
    "\n",
    "- Implementação de Skip-gram\n",
    "- 10 épocas\n",
    "- Tamanho dos embeddings como 3\n",
    "- Tamanho da janela de contexto como 25\n",
    "- Média de erro de 0.114\n",
    "\n",
    "Percebe-se que de modo geral para todos os conjuntos de instâncias realizadas, a implementação do Skip-Gram obteve melhores resultados em comparação ao Cbow. O mesmo vale para o tamanho dos embeddings em que conforme o tamanho diminua, melhor ficava o valor do erro encontrado. Isso é válido pensando que o corpus utilizado para treino é relativamente pequeno, e portanto, embeddings menores são mais eficazes visto que menos informação precisa ser codificada. Também é válido dizer que como o corpus apresenta informações de diferentes contexots, com menores tamanhos de embedding é possível generalizar melhor a informação coletada.\n",
    "\n",
    "Sobre a janela de contexto, percebe-se no geral que melhores resultados foram obtidos com valores mais altos. Isso é válido na tarefa de classificação de analogias em que é importante observar o uso de conjunto de palavras para entender o contexto em que a palavra está inserida. Mostrando assim os bons resultados vistos na prática. Sobre o número de épocas pequeno, como o tamanho do corpus é pequeno, não é necessário muitas épocas para treinar o modelo, visto que rapidamente é possível aprender boas representações de palavras.\n",
    "\n",
    "Analogamente aos resultados obtidos, é possível de se comentar sobre as execuções negativas também:\n",
    "\n",
    "- Implementação de Cbow\n",
    "- 3 épocas\n",
    "- Tamanho dos embeddings como 50\n",
    "- Tamanho da janela de contexto como 5\n",
    "- Média de erro de 0.90\n",
    "\n",
    "O mesmo vale para outros testes feitos.\n",
    "\n",
    "- Implementação de Cbow\n",
    "- 5 épocas\n",
    "- Tamanho dos embeddings como 200\n",
    "- Tamanho da janela de contexto como 5\n",
    "- Média de erro de 0.898\n",
    "\n",
    "Desse modo, um possível fator impactante foi o algoritmo Cbow, presente em todos os piores resultados. Mesmo que se observe a tendência do Cbow performar melhor com mais épocas e menores tamanho de vetor, o impacto ainda foi grande de se utlizar o algoritmo, sendo essa combinação de parâmetros não performática para a tarefa em questão.\n",
    "\n",
    "Vale destacar no entanto que outros testes foram feitos tendo em vista a variação de parâmetros, obtendo diferentes resultados como observados no final do notebook no arquivo 'results_evaluate_word_analogies'. Essa função retorna o resultado em relação a acurácia de classificação de analogias, não utilizando somente a distância como fator de avaliação. Esses resultados mostraram que, para os modelos anteriores, a acurácia de classificação de analogias foi de 0.0, mostrando que o modelo não conseguiu classificar nenhuma analogia corretamente (embora o erro calculado pela similaridade de cosseno tenha sido pequeno). Já utilizando a acurácia como métrica de avaliação, a melhor configuração foi:\n",
    "\n",
    "- Implementação de Skip-gram\n",
    "- 10 épocas\n",
    "- Tamanho dos embeddings como 250\n",
    "- Tamanho da janela de contexto como 25\n",
    "- Acurácia de 0.3652886071689011\n",
    "\n",
    "Isso segue no sentido contrário aos resultados obtidos anteriormente utilizando a similaridade de cosseno. Tais resultados são válidos tendo em vista que a acurácia de classificação de analogias é uma métrica mais robusta para avaliação do modelo. Nos testes anteriores, como o espaço de embeddings é pequeno, a similaridade de cosseno vai obter pouca variação, assim, diminuir a dimensionalidade auxilia na melhora da métrica. No entanto, considerando a acurácia como avaliação, são privilegiados modelos que conseguem acomodar as palavras de maneira mais condizente no espaço vetorial, favorecendo assim modelos com alta dimensionalidade. Desse modo, é possível explicar a diferença dos resultados utilizando ambas as métricas.\n",
    "\n",
    "Portanto, ao final do trabalho o objetivo foi cumprido, com diversas variações de parâmetros sendo testadas, juntamente a diferentes métricas de avaliação, exercitando o funcionamento do modelo Word2Vec e a importância de se escolher os parâmetros corretos para a tarefa em questão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abrindo arquivo de corpus\n",
    "with open('text8') as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " anarchism o\n"
     ]
    }
   ],
   "source": [
    "print(data[0:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organizando entrada, tokenizando em sentenças de tamanho 50 (valor arbitrario)\n",
    "data_sentences = []\n",
    "sentences = []\n",
    "for i in data.split():\n",
    "    sentences.append(i)\n",
    "\n",
    "    if len(sentences) == 50:\n",
    "        data_sentences.append(sentences)\n",
    "        sentences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against', 'early', 'working', 'class', 'radicals', 'including', 'the', 'diggers', 'of', 'the', 'english', 'revolution', 'and', 'the', 'sans', 'culottes', 'of', 'the', 'french', 'revolution', 'whilst', 'the', 'term', 'is', 'still', 'used', 'in', 'a', 'pejorative', 'way', 'to', 'describe', 'any', 'act', 'that', 'used', 'violent', 'means', 'to', 'destroy', 'the'], ['organization', 'of', 'society', 'it', 'has', 'also', 'been', 'taken', 'up', 'as', 'a', 'positive', 'label', 'by', 'self', 'defined', 'anarchists', 'the', 'word', 'anarchism', 'is', 'derived', 'from', 'the', 'greek', 'without', 'archons', 'ruler', 'chief', 'king', 'anarchism', 'as', 'a', 'political', 'philosophy', 'is', 'the', 'belief', 'that', 'rulers', 'are', 'unnecessary', 'and', 'should', 'be', 'abolished', 'although', 'there', 'are', 'differing'], ['interpretations', 'of', 'what', 'this', 'means', 'anarchism', 'also', 'refers', 'to', 'related', 'social', 'movements', 'that', 'advocate', 'the', 'elimination', 'of', 'authoritarian', 'institutions', 'particularly', 'the', 'state', 'the', 'word', 'anarchy', 'as', 'most', 'anarchists', 'use', 'it', 'does', 'not', 'imply', 'chaos', 'nihilism', 'or', 'anomie', 'but', 'rather', 'a', 'harmonious', 'anti', 'authoritarian', 'society', 'in', 'place', 'of', 'what', 'are', 'regarded'], ['as', 'authoritarian', 'political', 'structures', 'and', 'coercive', 'economic', 'institutions', 'anarchists', 'advocate', 'social', 'relations', 'based', 'upon', 'voluntary', 'association', 'of', 'autonomous', 'individuals', 'mutual', 'aid', 'and', 'self', 'governance', 'while', 'anarchism', 'is', 'most', 'easily', 'defined', 'by', 'what', 'it', 'is', 'against', 'anarchists', 'also', 'offer', 'positive', 'visions', 'of', 'what', 'they', 'believe', 'to', 'be', 'a', 'truly', 'free', 'society'], ['however', 'ideas', 'about', 'how', 'an', 'anarchist', 'society', 'might', 'work', 'vary', 'considerably', 'especially', 'with', 'respect', 'to', 'economics', 'there', 'is', 'also', 'disagreement', 'about', 'how', 'a', 'free', 'society', 'might', 'be', 'brought', 'about', 'origins', 'and', 'predecessors', 'kropotkin', 'and', 'others', 'argue', 'that', 'before', 'recorded', 'history', 'human', 'society', 'was', 'organized', 'on', 'anarchist', 'principles', 'most', 'anthropologists', 'follow']]\n"
     ]
    }
   ],
   "source": [
    "print(data_sentences[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparando hiperparametros para serem usados (dados da última iteração para testes)\n",
    "hiperparameters = {\n",
    "    'vector_size': [100, 200, 250],\n",
    "    'sg': [0, 1], # 1 = skip-gram, 0 = CBOW\n",
    "    'window': [10, 20, 25],\n",
    "    'epochs': [5, 10],\n",
    "}\n",
    "\n",
    "grid = list(ParameterGrid(hiperparameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19544\n"
     ]
    }
   ],
   "source": [
    "# preparando informações para teste que estão presentes no arquivo questions-words.txt\n",
    "test_vectors = []\n",
    "target_words = []\n",
    "with open(\"questions-words.txt\") as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\":\"):\n",
    "                continue\n",
    "            \n",
    "            line = line.strip().lower().split(' ')\n",
    "\n",
    "            if len(line) != 4:\n",
    "                 continue\n",
    "            \n",
    "            # seleciono informações de teste e agrupo as palavras de analogias em listas\n",
    "            test_vectors.append(line[0:3])\n",
    "            target_words.append(line[3])      \n",
    "\n",
    "print(len(test_vectors))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treinando modelo word2vec com dados de entrada, variando os hiperparametros e calculando erro médio\n",
    "# a melhor e pior configuração são salvas e impressas ao final\n",
    "best_config = {}\n",
    "min_avg_error = 50000\n",
    "best_model_error = 0\n",
    "\n",
    "worst_config = {}\n",
    "max_avg_error = 0\n",
    "worst_model_error = 50000\n",
    "\n",
    "results = []\n",
    "\n",
    "# TESTES -> SIMILARIDADE DE COSSENO\n",
    "\n",
    "# dados estão no formato: palavra1 palavra2 palavra3 palavra4\n",
    "# a ideia é que palavra1 - palavra2 + palavra3 = palavra4\n",
    "# assim é calculada a similaridade de cosseno entre o resultado de palavra1 - palavra2 + palavra3 com a palavra4\n",
    "# e assim o erro é calculado como 1 - similaridade\n",
    "for parameter_configuration in grid: # testo todas as combinações de hiperparametros\n",
    "    total_error = 0.0\n",
    "    count_test_words_in_vocab = 0\n",
    "\n",
    "    model = Word2Vec(sentences=data_sentences, vector_size=parameter_configuration['vector_size'], window=parameter_configuration['window'], sg=parameter_configuration['sg'], epochs=parameter_configuration['epochs']) # faço a predição\n",
    "\n",
    "    for idx in range(len(test_vectors)):\n",
    "\n",
    "        word_a, word_b, word_c = test_vectors[idx]\n",
    "        target = target_words[idx]\n",
    " \n",
    "        if all(word in model.wv for word in [word_a, word_b, word_c, target]): # vejo se as palavras estão no vocabulário\n",
    "\n",
    "            analogy_vector = model.wv[word_a] - model.wv[word_b] + model.wv[word_c]\n",
    "            \n",
    "            similarity = cosine_similarity([analogy_vector], [model.wv[target]])[0][0] # comparo o target com a palavra retornada pelo modelo\n",
    "\n",
    "            # melhor erro é proximo de 0 \n",
    "            error = 1 - similarity\n",
    "            total_error += error\n",
    "            count_test_words_in_vocab += 1\n",
    "            \"\"\" print(f\"Analogy: {word_a} - {word_b} + {word_c} = {target}\")\n",
    "            print(f\"Similarity with {target}: {similarity:.4f}, Error: {error:.4f}\")\n",
    "            print() \"\"\"\n",
    "\n",
    "    # calculo o erro médio de todos as analogias realizadas\n",
    "    average_error = total_error / count_test_words_in_vocab \n",
    "    \"\"\" print(f\"\\nAverage Analogy Error: {average_error}\") \"\"\"\n",
    "\n",
    "    results.append((parameter_configuration, average_error))\n",
    "\n",
    "    if average_error < min_avg_error:\n",
    "        best_config = parameter_configuration\n",
    "        min_avg_error = average_error\n",
    "        model.save(\"best_model\")\n",
    "    \n",
    "    if average_error > max_avg_error:\n",
    "        worst_config = parameter_configuration\n",
    "        max_avg_error = average_error\n",
    "\n",
    "\n",
    "print(f\"\\nBest Configuration: {best_config}\")\n",
    "print(f\"Min Average Error: {min_avg_error}\")\n",
    "\n",
    "print(f\"\\nWorst Configuration: {worst_config}\")\n",
    "print(f\"Max Average Error: {max_avg_error}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treinando modelo word2vec com dados de entrada, variando os hiperparametros e calculando erro médio\n",
    "# a melhor e pior configuração são salvas e impressas ao final\n",
    "best_config = {}\n",
    "best_model_error = 0\n",
    "\n",
    "worst_config = {}\n",
    "worst_model_error = 50000\n",
    "\n",
    "results = []\n",
    "\n",
    "# TESTES -> ACURACIA\n",
    "\n",
    "# dados estão no formato: palavra1 palavra2 palavra3 palavra4\n",
    "# a ideia é que palavra1 - palavra2 + palavra3 = palavra4\n",
    "# assim é calculada a acuracia do resultado da operação vetorial com a palavra alvo (palavra4)\n",
    "# o calculo é feito com a função evaluate_word_analogies do gensim\n",
    "for parameter_configuration in grid: # testo todas as combinações de hiperparametros\n",
    "    total_error = 0.0\n",
    "    count_test_words_in_vocab = 0\n",
    "\n",
    "    model = Word2Vec(sentences=data_sentences, vector_size=parameter_configuration['vector_size'], window=parameter_configuration['window'], sg=parameter_configuration['sg'], epochs=parameter_configuration['epochs']) # faço a predição\n",
    "\n",
    "    result = model.wv.evaluate_word_analogies('questions-words.txt') # avalio o modelo com as palavras de teste\n",
    "\n",
    "    if result[0] > best_model_error:\n",
    "        best_config = parameter_configuration\n",
    "        best_model_error = result[0]\n",
    "        model.save(\"best_model\")\n",
    "\n",
    "    if result[0] < worst_model_error:\n",
    "        worst_config = parameter_configuration\n",
    "        worst_model_error = result[0]\n",
    "\n",
    "    results.append((parameter_configuration, result[0]))\n",
    "\n",
    "\n",
    "print(f\"\\nBest Configuration: {best_config}\")\n",
    "print(f\"Min Average Error: {min_avg_error}\")\n",
    "\n",
    "print(f\"\\nWorst Configuration: {worst_config}\")\n",
    "print(f\"Max Average Error: {max_avg_error}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvando resultados em um arquivo de texto\n",
    "results.sort(key=lambda x: x[1])\n",
    "\n",
    "with open(\"results_evaluate_word_analogies.txt\", \"w\") as f:\n",
    "    for result in results:\n",
    "        f.write(f\"{result[0]} -> {result[1]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados em consideraçao a acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores resultados - Conjunto 1 de teste\n",
      "{'epochs': 10, 'sg': 0, 'vector_size': 200, 'window': 20} -> 0.3620351152745835\n",
      "{'epochs': 10, 'sg': 0, 'vector_size': 200, 'window': 25} -> 0.36282044090424637\n",
      "{'epochs': 10, 'sg': 0, 'vector_size': 250, 'window': 20} -> 0.3629326302799125\n",
      "{'epochs': 10, 'sg': 1, 'vector_size': 200, 'window': 25} -> 0.3648398496662366\n",
      "{'epochs': 10, 'sg': 1, 'vector_size': 250, 'window': 25} -> 0.3652886071689011\n",
      "\n",
      "Piores resultados - Conjunto 1 de teste\n",
      "{'epochs': 5, 'sg': 0, 'vector_size': 100, 'window': 10} -> 0.25433331463510406\n",
      "{'epochs': 5, 'sg': 0, 'vector_size': 100, 'window': 20} -> 0.2600549727940764\n",
      "{'epochs': 5, 'sg': 0, 'vector_size': 100, 'window': 25} -> 0.2653839681382173\n",
      "{'epochs': 5, 'sg': 0, 'vector_size': 250, 'window': 10} -> 0.26919840691086555\n",
      "{'epochs': 5, 'sg': 0, 'vector_size': 200, 'window': 10} -> 0.27082515285802433\n"
     ]
    }
   ],
   "source": [
    "# imprimindo resultados\n",
    "with open(\"results_evaluate_word_analogies.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "        \n",
    "    # 5 melhores resultados\n",
    "    print(\"Melhores resultados - Conjunto 1 de teste\")\n",
    "    for line in lines[-5:]:\n",
    "        print(line.strip())\n",
    "\n",
    "    print()\n",
    "\n",
    "    # 5 piores resultados\n",
    "    print(\"Piores resultados - Conjunto 1 de teste\")\n",
    "    for line in lines[:5]:\n",
    "        print(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados em consideração a similaridade de cosseno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores resultados - Conjunto 1 de teste\n",
      "{'epochs': 5, 'sg': 1, 'vector_size': 50, 'window': 10} -> 0.55538132695304\n",
      "{'epochs': 10, 'sg': 1, 'vector_size': 50, 'window': 10} -> 0.5600422201176011\n",
      "{'epochs': 20, 'sg': 1, 'vector_size': 50, 'window': 10} -> 0.5707512863907391\n",
      "{'epochs': 5, 'sg': 1, 'vector_size': 50, 'window': 5} -> 0.5774646656031192\n",
      "{'epochs': 10, 'sg': 1, 'vector_size': 50, 'window': 5} -> 0.584635035953901\n",
      "\n",
      "Piores resultados - Conjunto 1 de teste\n",
      "{'epochs': 5, 'sg': 0, 'vector_size': 200, 'window': 10} -> 0.8830664120799637\n",
      "{'epochs': 5, 'sg': 0, 'vector_size': 200, 'window': 2} -> 0.8836903947134177\n",
      "{'epochs': 5, 'sg': 0, 'vector_size': 50, 'window': 5} -> 0.8844702592285507\n",
      "{'epochs': 5, 'sg': 0, 'vector_size': 100, 'window': 5} -> 0.8917970729349668\n",
      "{'epochs': 5, 'sg': 0, 'vector_size': 200, 'window': 5} -> 0.8978691275613163\n"
     ]
    }
   ],
   "source": [
    "# imprimindo os resultados -> piores resultados\n",
    "with open(\"results1.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "        \n",
    "    # 5 melhores resultados\n",
    "    print(\"Melhores resultados - Conjunto 1 de teste\")\n",
    "    for line in lines[:5]:\n",
    "        print(line.strip())\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # 5 piores resultados\n",
    "    print(\"Piores resultados - Conjunto 1 de teste\")\n",
    "    for line in lines[-5:]:\n",
    "        print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores resultados - Conjunto 2 de teste\n",
      "{'epochs': 5, 'sg': 1, 'vector_size': 15, 'window': 10} -> 0.38703091299607423\n",
      "{'epochs': 8, 'sg': 1, 'vector_size': 15, 'window': 10} -> 0.38780395781142457\n",
      "{'epochs': 3, 'sg': 1, 'vector_size': 15, 'window': 10} -> 0.39179346938399207\n",
      "{'epochs': 8, 'sg': 1, 'vector_size': 15, 'window': 5} -> 0.40069795448117645\n",
      "{'epochs': 5, 'sg': 1, 'vector_size': 15, 'window': 5} -> 0.4125249547295823\n",
      "\n",
      "Piores resultados - Conjunto 2 de teste\n",
      "{'epochs': 5, 'sg': 0, 'vector_size': 50, 'window': 5} -> 0.8870883486498904\n",
      "{'epochs': 3, 'sg': 0, 'vector_size': 30, 'window': 10} -> 0.8881735312187637\n",
      "{'epochs': 3, 'sg': 0, 'vector_size': 50, 'window': 10} -> 0.8969098171314653\n",
      "{'epochs': 3, 'sg': 0, 'vector_size': 30, 'window': 5} -> 0.8986601603363565\n",
      "{'epochs': 3, 'sg': 0, 'vector_size': 50, 'window': 5} -> 0.9022114387767982\n"
     ]
    }
   ],
   "source": [
    "# imprimindo os resultados\n",
    "with open(\"results2.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "        \n",
    "    # 5 melhores resultados\n",
    "    print(\"Melhores resultados - Conjunto 2 de teste\")\n",
    "    for line in lines[:5]:\n",
    "        print(line.strip())\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # 5 piores resultados\n",
    "    print(\"Piores resultados - Conjunto 2 de teste\")\n",
    "    for line in lines[-5:]:\n",
    "        print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores resultados - Conjunto 3 de teste\n",
      "{'epochs': 8, 'sg': 1, 'vector_size': 10, 'window': 15} -> 0.2954936634862853\n",
      "{'epochs': 5, 'sg': 1, 'vector_size': 10, 'window': 15} -> 0.30072306892771716\n",
      "{'epochs': 3, 'sg': 1, 'vector_size': 10, 'window': 15} -> 0.31008412199108054\n",
      "{'epochs': 3, 'sg': 1, 'vector_size': 10, 'window': 10} -> 0.31038375133059615\n",
      "{'epochs': 5, 'sg': 1, 'vector_size': 10, 'window': 10} -> 0.3192339427661957\n",
      "\n",
      "Piores resultados - Conjunto 3 de teste\n",
      "{'epochs': 5, 'sg': 0, 'vector_size': 30, 'window': 10} -> 0.8634177259757336\n",
      "{'epochs': 5, 'sg': 0, 'vector_size': 30, 'window': 5} -> 0.8660574117078195\n",
      "{'epochs': 3, 'sg': 0, 'vector_size': 30, 'window': 15} -> 0.8798409598996422\n",
      "{'epochs': 3, 'sg': 0, 'vector_size': 30, 'window': 10} -> 0.8860237199068711\n",
      "{'epochs': 3, 'sg': 0, 'vector_size': 30, 'window': 5} -> 0.8976718970943462\n"
     ]
    }
   ],
   "source": [
    "# imprimindo os resultados\n",
    "with open(\"results3.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "        \n",
    "    # 5 melhores resultados\n",
    "    print(\"Melhores resultados - Conjunto 3 de teste\")\n",
    "    for line in lines[:5]:\n",
    "        print(line.strip())\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # 5 piores resultados\n",
    "    print(\"Piores resultados - Conjunto 3 de teste\")\n",
    "    for line in lines[-5:]:\n",
    "        print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores resultados - Conjunto 4 de teste\n",
      "{'epochs': 8, 'sg': 1, 'vector_size': 5, 'window': 20} -> 0.19574313511324876\n",
      "{'epochs': 5, 'sg': 1, 'vector_size': 5, 'window': 20} -> 0.19791436021546593\n",
      "{'epochs': 3, 'sg': 1, 'vector_size': 5, 'window': 20} -> 0.199327464784689\n",
      "{'epochs': 5, 'sg': 1, 'vector_size': 5, 'window': 15} -> 0.20131631473280664\n",
      "{'epochs': 8, 'sg': 1, 'vector_size': 5, 'window': 15} -> 0.20434490671463792\n",
      "\n",
      "Piores resultados - Conjunto 4 de teste\n",
      "{'epochs': 3, 'sg': 0, 'vector_size': 5, 'window': 10} -> 0.8056594325398947\n",
      "{'epochs': 3, 'sg': 0, 'vector_size': 10, 'window': 20} -> 0.8077876065773347\n",
      "{'epochs': 3, 'sg': 0, 'vector_size': 7, 'window': 15} -> 0.8118513876709923\n",
      "{'epochs': 3, 'sg': 0, 'vector_size': 10, 'window': 15} -> 0.8121803097646034\n",
      "{'epochs': 3, 'sg': 0, 'vector_size': 10, 'window': 10} -> 0.8218598262022079\n"
     ]
    }
   ],
   "source": [
    "# imprimindo os resultados\n",
    "with open(\"results4.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "        \n",
    "    # 5 melhores resultados\n",
    "    print(\"Melhores resultados - Conjunto 4 de teste\")\n",
    "    for line in lines[:5]:\n",
    "        print(line.strip())\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # 5 piores resultados\n",
    "    print(\"Piores resultados - Conjunto 4 de teste\")\n",
    "    for line in lines[-5:]:\n",
    "        print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores resultados - Conjunto 5 de teste\n",
      "{'epochs': 10, 'sg': 1, 'vector_size': 3, 'window': 25} -> 0.11449590156785465\n",
      "{'epochs': 8, 'sg': 1, 'vector_size': 3, 'window': 25} -> 0.12627258985665643\n",
      "{'epochs': 10, 'sg': 1, 'vector_size': 3, 'window': 20} -> 0.12849591586262585\n",
      "{'epochs': 8, 'sg': 1, 'vector_size': 3, 'window': 20} -> 0.13624663163420458\n",
      "{'epochs': 5, 'sg': 1, 'vector_size': 3, 'window': 25} -> 0.14409597154196624\n",
      "\n",
      "Piores resultados - Conjunto 5 de teste\n",
      "{'epochs': 5, 'sg': 0, 'vector_size': 7, 'window': 25} -> 0.737519417538554\n",
      "{'epochs': 5, 'sg': 0, 'vector_size': 7, 'window': 20} -> 0.7466540246473996\n",
      "{'epochs': 5, 'sg': 0, 'vector_size': 5, 'window': 20} -> 0.7484880196498578\n",
      "{'epochs': 5, 'sg': 0, 'vector_size': 7, 'window': 15} -> 0.7554935015382345\n",
      "{'epochs': 5, 'sg': 0, 'vector_size': 5, 'window': 15} -> 0.7583584528408859\n"
     ]
    }
   ],
   "source": [
    "# imprimindo os resultados -> melhores resultados\n",
    "with open(\"results5.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "        \n",
    "    # 5 melhores resultados\n",
    "    print(\"Melhores resultados - Conjunto 5 de teste\")\n",
    "    for line in lines[:5]:\n",
    "        print(line.strip())\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # 5 piores resultados\n",
    "    print(\"Piores resultados - Conjunto 5 de teste\")\n",
    "    for line in lines[-5:]:\n",
    "        print(line.strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp1_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
