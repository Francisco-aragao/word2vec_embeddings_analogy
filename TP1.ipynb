{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Francisco Teixeira Rocha Aragão\n",
    "### 2021031726\n",
    "### Tp1 - Processamento de Linguagem Natural\n",
    "\n",
    "#### Objetivo: Testar diferentes variações de parametros para utilização do modelo Word2vec para a tarefa de verificação de analogias utilizando operações de subtração e adição de vetores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abrindo arquivo de corpus\n",
    "with open('text8') as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " anarchism o\n"
     ]
    }
   ],
   "source": [
    "print(data[0:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organizando entrada, tokenizando em sentenças de tamanho 50 (valor arbitrario)\n",
    "data_sentences = []\n",
    "sentences = []\n",
    "for i in data.split():\n",
    "    sentences.append(i)\n",
    "\n",
    "    if len(sentences) == 50:\n",
    "        data_sentences.append(sentences)\n",
    "        sentences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against', 'early', 'working', 'class', 'radicals', 'including', 'the', 'diggers', 'of', 'the', 'english', 'revolution', 'and', 'the', 'sans', 'culottes', 'of', 'the', 'french', 'revolution', 'whilst', 'the', 'term', 'is', 'still', 'used', 'in', 'a', 'pejorative', 'way', 'to', 'describe', 'any', 'act', 'that', 'used', 'violent', 'means', 'to', 'destroy', 'the'], ['organization', 'of', 'society', 'it', 'has', 'also', 'been', 'taken', 'up', 'as', 'a', 'positive', 'label', 'by', 'self', 'defined', 'anarchists', 'the', 'word', 'anarchism', 'is', 'derived', 'from', 'the', 'greek', 'without', 'archons', 'ruler', 'chief', 'king', 'anarchism', 'as', 'a', 'political', 'philosophy', 'is', 'the', 'belief', 'that', 'rulers', 'are', 'unnecessary', 'and', 'should', 'be', 'abolished', 'although', 'there', 'are', 'differing'], ['interpretations', 'of', 'what', 'this', 'means', 'anarchism', 'also', 'refers', 'to', 'related', 'social', 'movements', 'that', 'advocate', 'the', 'elimination', 'of', 'authoritarian', 'institutions', 'particularly', 'the', 'state', 'the', 'word', 'anarchy', 'as', 'most', 'anarchists', 'use', 'it', 'does', 'not', 'imply', 'chaos', 'nihilism', 'or', 'anomie', 'but', 'rather', 'a', 'harmonious', 'anti', 'authoritarian', 'society', 'in', 'place', 'of', 'what', 'are', 'regarded'], ['as', 'authoritarian', 'political', 'structures', 'and', 'coercive', 'economic', 'institutions', 'anarchists', 'advocate', 'social', 'relations', 'based', 'upon', 'voluntary', 'association', 'of', 'autonomous', 'individuals', 'mutual', 'aid', 'and', 'self', 'governance', 'while', 'anarchism', 'is', 'most', 'easily', 'defined', 'by', 'what', 'it', 'is', 'against', 'anarchists', 'also', 'offer', 'positive', 'visions', 'of', 'what', 'they', 'believe', 'to', 'be', 'a', 'truly', 'free', 'society'], ['however', 'ideas', 'about', 'how', 'an', 'anarchist', 'society', 'might', 'work', 'vary', 'considerably', 'especially', 'with', 'respect', 'to', 'economics', 'there', 'is', 'also', 'disagreement', 'about', 'how', 'a', 'free', 'society', 'might', 'be', 'brought', 'about', 'origins', 'and', 'predecessors', 'kropotkin', 'and', 'others', 'argue', 'that', 'before', 'recorded', 'history', 'human', 'society', 'was', 'organized', 'on', 'anarchist', 'principles', 'most', 'anthropologists', 'follow'], ['kropotkin', 'and', 'engels', 'in', 'believing', 'that', 'hunter', 'gatherer', 'bands', 'were', 'egalitarian', 'and', 'lacked', 'division', 'of', 'labour', 'accumulated', 'wealth', 'or', 'decreed', 'law', 'and', 'had', 'equal', 'access', 'to', 'resources', 'william', 'godwin', 'anarchists', 'including', 'the', 'the', 'anarchy', 'organisation', 'and', 'rothbard', 'find', 'anarchist', 'attitudes', 'in', 'taoism', 'from', 'ancient', 'china', 'kropotkin', 'found', 'similar', 'ideas', 'in'], ['stoic', 'zeno', 'of', 'citium', 'according', 'to', 'kropotkin', 'zeno', 'repudiated', 'the', 'omnipotence', 'of', 'the', 'state', 'its', 'intervention', 'and', 'regimentation', 'and', 'proclaimed', 'the', 'sovereignty', 'of', 'the', 'moral', 'law', 'of', 'the', 'individual', 'the', 'anabaptists', 'of', 'one', 'six', 'th', 'century', 'europe', 'are', 'sometimes', 'considered', 'to', 'be', 'religious', 'forerunners', 'of', 'modern', 'anarchism', 'bertrand', 'russell', 'in'], ['his', 'history', 'of', 'western', 'philosophy', 'writes', 'that', 'the', 'anabaptists', 'repudiated', 'all', 'law', 'since', 'they', 'held', 'that', 'the', 'good', 'man', 'will', 'be', 'guided', 'at', 'every', 'moment', 'by', 'the', 'holy', 'spirit', 'from', 'this', 'premise', 'they', 'arrive', 'at', 'communism', 'the', 'diggers', 'or', 'true', 'levellers', 'were', 'an', 'early', 'communistic', 'movement', 'during', 'the', 'time', 'of'], ['the', 'english', 'civil', 'war', 'and', 'are', 'considered', 'by', 'some', 'as', 'forerunners', 'of', 'modern', 'anarchism', 'in', 'the', 'modern', 'era', 'the', 'first', 'to', 'use', 'the', 'term', 'to', 'mean', 'something', 'other', 'than', 'chaos', 'was', 'louis', 'armand', 'baron', 'de', 'lahontan', 'in', 'his', 'nouveaux', 'voyages', 'dans', 'l', 'am', 'rique', 'septentrionale', 'one', 'seven', 'zero', 'three', 'where'], ['he', 'described', 'the', 'indigenous', 'american', 'society', 'which', 'had', 'no', 'state', 'laws', 'prisons', 'priests', 'or', 'private', 'property', 'as', 'being', 'in', 'anarchy', 'russell', 'means', 'a', 'libertarian', 'and', 'leader', 'in', 'the', 'american', 'indian', 'movement', 'has', 'repeatedly', 'stated', 'that', 'he', 'is', 'an', 'anarchist', 'and', 'so', 'are', 'all', 'his', 'ancestors', 'in', 'one', 'seven', 'nine', 'three'], ['in', 'the', 'thick', 'of', 'the', 'french', 'revolution', 'william', 'godwin', 'published', 'an', 'enquiry', 'concerning', 'political', 'justice', 'although', 'godwin', 'did', 'not', 'use', 'the', 'word', 'anarchism', 'many', 'later', 'anarchists', 'have', 'regarded', 'this', 'book', 'as', 'the', 'first', 'major', 'anarchist', 'text', 'and', 'godwin', 'as', 'the', 'founder', 'of', 'philosophical', 'anarchism', 'but', 'at', 'this', 'point', 'no', 'anarchist']]\n"
     ]
    }
   ],
   "source": [
    "print(data_sentences[0:11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLICAR O MOTIVO DESSES PARAMETROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparando hiperparametros para serem usados\n",
    "hiperparameters = {\n",
    "    'vector_size': [3, 5, 7],\n",
    "    'sg': [0, 1], # 1 = skip-gram, 0 = CBOW\n",
    "    'window': [15, 20, 25],\n",
    "    'epochs': [5, 8, 10],\n",
    "}\n",
    "\n",
    "grid = list(ParameterGrid(hiperparameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19544\n"
     ]
    }
   ],
   "source": [
    "# preparando informações para teste que estão presentes no arquivo questions-words.txt\n",
    "test_vectors = []\n",
    "target_words = []\n",
    "with open(\"questions-words.txt\") as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\":\"):\n",
    "                continue\n",
    "            \n",
    "            line = line.strip().lower().split(' ')\n",
    "\n",
    "            if len(line) != 4:\n",
    "                 continue\n",
    "            \n",
    "            test_vectors.append(line[0:3])\n",
    "            target_words.append(line[3])      \n",
    "\n",
    "print(len(test_vectors))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Configuration: {'epochs': 10, 'sg': 1, 'vector_size': 3, 'window': 25}\n",
      "Min Average Error: 0.11449590156785465\n",
      "\n",
      "Worst Configuration: {'epochs': 5, 'sg': 0, 'vector_size': 5, 'window': 15}\n",
      "Max Average Error: 0.7583584528408859\n"
     ]
    }
   ],
   "source": [
    "# treinando modelo word2vec com dados de entrada, variando os hiperparametros e calculando erro médio\n",
    "# a melhor e pior configuração são salvas e impressas ao final\n",
    "best_config = {}\n",
    "min_avg_error = 50000\n",
    "\n",
    "worst_config = {}\n",
    "max_avg_error = 0\n",
    "\n",
    "results = []\n",
    "\n",
    "# dados estão no formato: palavra1 palavra2 palavra3 palavra4\n",
    "# a ideia é que palavra1 - palavra2 + palavra3 = palavra4\n",
    "# assim é calculada a similaridade de cosseno entre o resultado de palavra1 - palavra2 + palavra3 com a palavra4\n",
    "# e assim o erro é calculado como 1 - similaridade\n",
    "for parameter_configuration in grid:\n",
    "    total_error = 0.0\n",
    "    count_test_words_in_vocab = 0\n",
    "\n",
    "    model = Word2Vec(sentences=data_sentences, vector_size=parameter_configuration['vector_size'], window=parameter_configuration['window'], sg=parameter_configuration['sg'], epochs=parameter_configuration['epochs'])\n",
    "\n",
    "    for idx in range(len(test_vectors)):\n",
    "\n",
    "        # Extract the words in the analogy\n",
    "        word_a, word_b, word_c = test_vectors[idx]\n",
    "        target = target_words[idx]\n",
    "\n",
    "        if all(word in model.wv for word in [word_a, word_b, word_c, target]):\n",
    "\n",
    "            analogy_vector = model.wv[word_a] - model.wv[word_b] + model.wv[word_c]\n",
    "            \n",
    "            similarity = cosine_similarity([analogy_vector], [model.wv[target]])[0][0]\n",
    "\n",
    "            # melhor erro é proximo de 0 \n",
    "            error = 1 - similarity\n",
    "            total_error += error\n",
    "            count_test_words_in_vocab += 1\n",
    "            \"\"\" print(f\"Analogy: {word_a} - {word_b} + {word_c} = {target}\")\n",
    "            print(f\"Similarity with {target}: {similarity:.4f}, Error: {error:.4f}\")\n",
    "            print() \"\"\"\n",
    "\n",
    "    \n",
    "    average_error = total_error / count_test_words_in_vocab \n",
    "    \"\"\" print(f\"\\nAverage Analogy Error: {average_error}\") \"\"\"\n",
    "\n",
    "    results.append((parameter_configuration, average_error))\n",
    "\n",
    "    if average_error < min_avg_error:\n",
    "        best_config = parameter_configuration\n",
    "        min_avg_error = average_error\n",
    "        model.save(\"best_model\")\n",
    "    \n",
    "    if average_error > max_avg_error:\n",
    "        worst_config = parameter_configuration\n",
    "        max_avg_error = average_error\n",
    "\n",
    "\n",
    "print(f\"\\nBest Configuration: {best_config}\")\n",
    "print(f\"Min Average Error: {min_avg_error}\")\n",
    "\n",
    "print(f\"\\nWorst Configuration: {worst_config}\")\n",
    "print(f\"Max Average Error: {max_avg_error}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segundo os resultados acima, a melhor configuração de parametros para o modelo Word2vec com o texto de entrada utilizado é a seguinte:\n",
    "- Dimensão do embedding: 50\n",
    "- Janela de contexto: 5\n",
    "- Iterações: 5\n",
    "- Algoritmo: Skip-gram\n",
    "--> Resultando em um erro de 0.55 ao avaliar as analogias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvando resultados em um arquivo de texto\n",
    "results.sort(key=lambda x: x[1])\n",
    "\n",
    "with open(\"results5.txt\", \"w\") as f:\n",
    "    for result in results:\n",
    "        f.write(f\"{result[0]} -> {result[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 10, 'sg': 1, 'vector_size': 3, 'window': 25} -> 0.11449590156785465\n",
      "\n",
      "{'epochs': 8, 'sg': 1, 'vector_size': 3, 'window': 25} -> 0.12627258985665643\n",
      "\n",
      "{'epochs': 10, 'sg': 1, 'vector_size': 3, 'window': 20} -> 0.12849591586262585\n",
      "\n",
      "{'epochs': 8, 'sg': 1, 'vector_size': 3, 'window': 20} -> 0.13624663163420458\n",
      "\n",
      "{'epochs': 5, 'sg': 1, 'vector_size': 3, 'window': 25} -> 0.14409597154196624\n",
      "\n",
      "{'epochs': 5, 'sg': 1, 'vector_size': 3, 'window': 20} -> 0.14422278522447513\n",
      "\n",
      "{'epochs': 10, 'sg': 1, 'vector_size': 3, 'window': 15} -> 0.1447926147206644\n",
      "\n",
      "{'epochs': 5, 'sg': 1, 'vector_size': 3, 'window': 15} -> 0.1464375747006119\n",
      "\n",
      "{'epochs': 8, 'sg': 1, 'vector_size': 3, 'window': 15} -> 0.14745602682742742\n",
      "\n",
      "{'epochs': 10, 'sg': 1, 'vector_size': 5, 'window': 25} -> 0.18509010214225952\n",
      "\n",
      "{'epochs': 10, 'sg': 1, 'vector_size': 5, 'window': 20} -> 0.19023491457267575\n",
      "\n",
      "{'epochs': 8, 'sg': 1, 'vector_size': 5, 'window': 25} -> 0.19100256810465152\n",
      "\n",
      "{'epochs': 8, 'sg': 1, 'vector_size': 5, 'window': 20} -> 0.1960823195610828\n",
      "\n",
      "{'epochs': 5, 'sg': 1, 'vector_size': 5, 'window': 25} -> 0.19889669370008792\n",
      "\n",
      "{'epochs': 5, 'sg': 1, 'vector_size': 5, 'window': 20} -> 0.19973682030202056\n",
      "\n",
      "{'epochs': 5, 'sg': 1, 'vector_size': 5, 'window': 15} -> 0.20054092033975546\n",
      "\n",
      "{'epochs': 10, 'sg': 1, 'vector_size': 5, 'window': 15} -> 0.20182318532197335\n",
      "\n",
      "{'epochs': 8, 'sg': 1, 'vector_size': 5, 'window': 15} -> 0.20302915237510685\n",
      "\n",
      "{'epochs': 8, 'sg': 1, 'vector_size': 7, 'window': 25} -> 0.22584369907968274\n",
      "\n",
      "{'epochs': 10, 'sg': 1, 'vector_size': 7, 'window': 25} -> 0.23463992261115674\n",
      "\n",
      "{'epochs': 10, 'sg': 1, 'vector_size': 7, 'window': 20} -> 0.23650161730379549\n",
      "\n",
      "{'epochs': 5, 'sg': 1, 'vector_size': 7, 'window': 15} -> 0.2389589579817044\n",
      "\n",
      "{'epochs': 5, 'sg': 1, 'vector_size': 7, 'window': 25} -> 0.23916582698493014\n",
      "\n",
      "{'epochs': 8, 'sg': 1, 'vector_size': 7, 'window': 20} -> 0.24036744557875467\n",
      "\n",
      "{'epochs': 8, 'sg': 1, 'vector_size': 7, 'window': 15} -> 0.24116442022778958\n",
      "\n",
      "{'epochs': 5, 'sg': 1, 'vector_size': 7, 'window': 20} -> 0.24386752631178094\n",
      "\n",
      "{'epochs': 10, 'sg': 1, 'vector_size': 7, 'window': 15} -> 0.2448239342472452\n",
      "\n",
      "{'epochs': 10, 'sg': 0, 'vector_size': 3, 'window': 20} -> 0.6075993755778518\n",
      "\n",
      "{'epochs': 10, 'sg': 0, 'vector_size': 3, 'window': 25} -> 0.6078594166317923\n",
      "\n",
      "{'epochs': 8, 'sg': 0, 'vector_size': 3, 'window': 25} -> 0.6146718501524926\n",
      "\n",
      "{'epochs': 5, 'sg': 0, 'vector_size': 3, 'window': 15} -> 0.624767131005262\n",
      "\n",
      "{'epochs': 8, 'sg': 0, 'vector_size': 3, 'window': 20} -> 0.6252532726512707\n",
      "\n",
      "{'epochs': 10, 'sg': 0, 'vector_size': 3, 'window': 15} -> 0.6306946183655793\n",
      "\n",
      "{'epochs': 5, 'sg': 0, 'vector_size': 3, 'window': 25} -> 0.6358008491928411\n",
      "\n",
      "{'epochs': 8, 'sg': 0, 'vector_size': 3, 'window': 15} -> 0.6380863779248827\n",
      "\n",
      "{'epochs': 5, 'sg': 0, 'vector_size': 3, 'window': 20} -> 0.6469184150579221\n",
      "\n",
      "{'epochs': 10, 'sg': 0, 'vector_size': 5, 'window': 25} -> 0.6700321610441227\n",
      "\n",
      "{'epochs': 10, 'sg': 0, 'vector_size': 5, 'window': 20} -> 0.6786613830440026\n",
      "\n",
      "{'epochs': 10, 'sg': 0, 'vector_size': 7, 'window': 25} -> 0.6825901129876294\n",
      "\n",
      "{'epochs': 8, 'sg': 0, 'vector_size': 5, 'window': 25} -> 0.6884714773238835\n",
      "\n",
      "{'epochs': 10, 'sg': 0, 'vector_size': 7, 'window': 20} -> 0.6912648273986861\n",
      "\n",
      "{'epochs': 8, 'sg': 0, 'vector_size': 7, 'window': 25} -> 0.6991574286007843\n",
      "\n",
      "{'epochs': 10, 'sg': 0, 'vector_size': 7, 'window': 15} -> 0.6999348453945352\n",
      "\n",
      "{'epochs': 10, 'sg': 0, 'vector_size': 5, 'window': 15} -> 0.7071847191868578\n",
      "\n",
      "{'epochs': 8, 'sg': 0, 'vector_size': 5, 'window': 20} -> 0.7089984134084225\n",
      "\n",
      "{'epochs': 8, 'sg': 0, 'vector_size': 7, 'window': 20} -> 0.7098294574621405\n",
      "\n",
      "{'epochs': 8, 'sg': 0, 'vector_size': 7, 'window': 15} -> 0.7152772778712354\n",
      "\n",
      "{'epochs': 8, 'sg': 0, 'vector_size': 5, 'window': 15} -> 0.7189687908619427\n",
      "\n",
      "{'epochs': 5, 'sg': 0, 'vector_size': 5, 'window': 25} -> 0.7319055082023944\n",
      "\n",
      "{'epochs': 5, 'sg': 0, 'vector_size': 7, 'window': 25} -> 0.737519417538554\n",
      "\n",
      "{'epochs': 5, 'sg': 0, 'vector_size': 7, 'window': 20} -> 0.7466540246473996\n",
      "\n",
      "{'epochs': 5, 'sg': 0, 'vector_size': 5, 'window': 20} -> 0.7484880196498578\n",
      "\n",
      "{'epochs': 5, 'sg': 0, 'vector_size': 7, 'window': 15} -> 0.7554935015382345\n",
      "\n",
      "{'epochs': 5, 'sg': 0, 'vector_size': 5, 'window': 15} -> 0.7583584528408859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lendo o arquivo de resultados\n",
    "with open(\"results5.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percebe-se acima que os menores erros foram obtidos fixando o algoritmo, tamanho do embedding e janela de contexto, variando assim apenas a quantidade de iterações. de maneira geral o fator que mais influenciou no erro foram baixas quantidade de iterações aliado a grande dimensões.\n",
    "\n",
    "Pelos resultados também foi-se visto que o algoritmo Skip-gram foi mais sensível aos parametros, tendo resultados variando de 0.55 até 0.77, enquanto o CBOW variou de 0.77 até 0.89."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp1_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
